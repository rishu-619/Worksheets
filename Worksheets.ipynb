{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Worksheets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPuGfNo2B6pbX4Ly9p4jdQd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishu-619/Worksheets/blob/master/Worksheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3eJc6QOwiwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a8f346c-3ab8-467b-fede-588c5fa3509b"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "def getTitle(url):\n",
        "    try:\n",
        "        html = urlopen(url)\n",
        "    except HTTPError as e:\n",
        "        return None\n",
        "    try:\n",
        "        bsObj = BeautifulSoup(html.read(), \"lxml\")\n",
        "        title = bsObj.body.h1\n",
        "    except AttributeError as e:\n",
        "        return None\n",
        "    return title\n",
        "print(getTitle(\"http://www.example.com/\"))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>Example Domain</h1>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sJWwn-gwqL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "c7a95470-c426-4c9f-95c7-755d2dcc38ec"
      },
      "source": [
        "!pip install icrawler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting icrawler\n",
            "  Downloading https://files.pythonhosted.org/packages/89/de/71d154b1fe181ee1a4afae5d10451856ef4689b3fd72d93cc55f31d2886a/icrawler-0.6.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from icrawler) (7.0.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from icrawler) (4.6.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from icrawler) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.6/dist-packages (from icrawler) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from icrawler) (4.2.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->icrawler) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->icrawler) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->icrawler) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.9.1->icrawler) (3.0.4)\n",
            "Installing collected packages: icrawler\n",
            "Successfully installed icrawler-0.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RB8y68twqmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "15953771-55b3-456d-a473-60e3841c0f3a"
      },
      "source": [
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "google_Crawler = GoogleImageCrawler(storage = {'root_dir': r'path'})\n",
        "\n",
        "google_Crawler.crawl(keyword = 'query', max_num = 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-27 16:32:07,176 - INFO - icrawler.crawler - start crawling...\n",
            "2020-08-27 16:32:07,177 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
            "2020-08-27 16:32:07,180 - INFO - feeder - thread feeder-001 exit\n",
            "2020-08-27 16:32:07,180 - INFO - icrawler.crawler - starting 1 parser threads...\n",
            "2020-08-27 16:32:07,184 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
            "2020-08-27 16:32:08,046 - INFO - parser - parsing result page https://www.google.com/search?q=query&ijn=0&start=0&tbs=&tbm=isch\n",
            "Exception in thread parser-001:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/icrawler/parser.py\", line 104, in worker_exec\n",
            "    for task in self.parse(response, **kwargs):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/icrawler/builtin/google.py\", line 157, in parse\n",
            "    meta = json.loads(txt)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "2020-08-27 16:32:12,189 - INFO - downloader - no more download task for thread downloader-001\n",
            "2020-08-27 16:32:12,191 - INFO - downloader - thread downloader-001 exit\n",
            "2020-08-27 16:32:12,194 - INFO - icrawler.crawler - Crawling task done!\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}